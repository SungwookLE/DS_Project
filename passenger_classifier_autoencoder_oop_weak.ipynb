{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "## After Train Autoencoder Feature Extractor, Fine tune design for Weak, OOP, ..."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "import importlib\n",
    "%matplotlib inline\n",
    "\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import LearningRateScheduler, EarlyStopping, ModelCheckpoint\n",
    "from tensorflow.keras.models import load_model\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "from load.load_data import load_opendata\n",
    "from load.load_data import load_mydata\n",
    "\n",
    "import utils.process\n",
    "importlib.reload(utils.process)\n",
    "from utils.process import preprocess, noise, augment, tsne_plot, display_pair, shuffler, label_dict_static, display_row, score, matching_plot\n",
    "\n",
    "import model.model_autoencoder"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Intialize the tensorflow-gpu <-> physical matching\n",
    "import tensorflow as tf\n",
    "\n",
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "    try:\n",
    "        # Currently, memory growth needs to be the same across GPUs\n",
    "        for gpu in gpus:\n",
    "            tf.config.experimental.set_memory_growth(gpu, True)\n",
    "        logical_gpus = tf.config.experimental.list_logical_devices('GPU')\n",
    "        print(len(gpus), \"Physical GPUs,\", len(logical_gpus), \"Logical GPUs\")\n",
    "    except RuntimeError as e:\n",
    "        # Memory growth must be set before GPUs have been initialized\n",
    "        print(e)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input\n",
    "\n",
    "model_load = load_model(\"./ckpt/model_oop_autoencoder_fine\")\n",
    "\n",
    "inputs = Input(shape=(64,64,3), name='encoder_input')\n",
    "x1 = model_load.layers[0](inputs)\n",
    "x2 = model_load.layers[1](x1)\n",
    "x3 = model_load.layers[3](x2)\n",
    "x4 = model_load.layers[4](x3)\n",
    "x5 = model_load.layers[5](x4)\n",
    "x6 = model_load.layers[6](x5)\n",
    "x7 = model_load.layers[7](x6)\n",
    "x8 = model_load.layers[8](x7)\n",
    "x9 = model_load.layers[9](x8)\n",
    "\n",
    "encoder = Model(inputs = inputs, outputs = x9, name='encoder')"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "encoder.trainable=False\n",
    "encoder.summary()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "import model.model_autoencoder\n",
    "importlib.reload(model.model_autoencoder)\n",
    "from model.model_autoencoder import model_classifier_with_encoder\n",
    "\n",
    "fin = model_classifier_with_encoder(encoder)\n",
    "fin.summary()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "tf.keras.utils.plot_model(fin)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 1. OOP train using encoder"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "## 1. Load & Prepare Data\n",
    "openloader = load_opendata()\n",
    "X_open, Y_open = openloader.load_data(classifier_label=\"OOP\", dsize=(64,64), comp_ratio=4)\n",
    "\n",
    "myloader = load_mydata()\n",
    "X_my, Y_my = myloader.load_data(classifier_label=\"OOP\", dsize=(64,64), comp_ratio=10, verbose=0)\n",
    "X_my_test, Y_my_test = myloader.load_test_data(classifier_label=\"OOP\", dsize=(64,64), comp_ratio=4, verbose=0)\n",
    "\n",
    "print(\"Open data is \", len(X_open),\", My Train set is \", len(Y_my),  \",  My Test set is \", len(Y_my_test))"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "## 2. Data Class Distribution\n",
    "count_center =0\n",
    "count_phone =0\n",
    "count_close =0\n",
    "count_far =0\n",
    "count_behind =0\n",
    "\n",
    "for idx, i in enumerate(Y_my):\n",
    "    if ( i == 'c0'):\n",
    "        count_center +=1\n",
    "    elif ( i == 'c1'):\n",
    "        count_phone+=1\n",
    "    elif ( i == 'c5'):\n",
    "        count_close+=1\n",
    "    elif ( i == 'c6'):\n",
    "        count_far+=1    \n",
    "    elif ( i == 'c7'):\n",
    "        count_behind+=1\n",
    "\n",
    "count_test_center =0\n",
    "count_test_phone =0\n",
    "count_test_close =0\n",
    "count_test_far =0\n",
    "count_test_behind =0\n",
    "\n",
    "for idx, i in enumerate(Y_my_test):\n",
    "    if ( i == 'c0'):\n",
    "        count_test_center +=1\n",
    "    elif ( i == 'c1'):\n",
    "        count_test_phone+=1\n",
    "    elif ( i == 'c5'):\n",
    "        count_test_close+=1\n",
    "    elif ( i == 'c6'):\n",
    "        count_test_far+=1    \n",
    "    elif ( i == 'c7'):\n",
    "        count_test_behind+=1\n",
    "\n",
    "count_open_center =0\n",
    "count_open_phone =0\n",
    "count_open_close =0\n",
    "count_open_far =0\n",
    "count_open_behind =0\n",
    "\n",
    "for idx, i in enumerate(Y_open):\n",
    "    if ( i == 'c0'):\n",
    "        count_open_center +=1\n",
    "    elif ( i == 'c1'):\n",
    "        count_open_phone+=1\n",
    "    elif ( i == 'c5'):\n",
    "        count_open_close+=1\n",
    "    elif ( i == 'c6'):\n",
    "        count_open_far+=1    \n",
    "    elif ( i == 'c7'):\n",
    "        count_open_behind+=1\n",
    "\n",
    "fig, (ax1, ax2, ax3) = plt.subplots(1,3, figsize=(10,5))\n",
    "plt.suptitle('labeled data distribution(ea) \\n (Trainset + Openset) is total Trainset')\n",
    "ax1.set_title('Trainset')\n",
    "ax1.bar(['center','phone', 'close', 'far', 'behind'],[count_center, count_phone, count_close, count_far, count_behind])\n",
    "ax2.set_title('Openset')\n",
    "ax2.bar(['center','phone', 'close', 'far', 'behind'],[count_open_center, count_open_phone, count_open_close, count_open_far, count_open_behind])\n",
    "ax3.set_title('Testset')\n",
    "ax3.bar(['center','phone', 'close', 'far', 'behind'],[count_test_center, count_test_phone, count_test_close, count_test_far, count_test_behind])\n",
    "\n",
    "plt.tight_layout()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "## 3. Data preprocessing\n",
    "\n",
    "# Normalized Image\n",
    "X1 = preprocess(X_my, shape = (64,64,3))\n",
    "X2 = preprocess(X_open, shape=(64,64,3))\n",
    "X = np.concatenate((X1, X2), axis=0)\n",
    "Y = np.concatenate((Y_my, Y_open), axis=0)\n",
    "\n",
    "X_test_oop = preprocess(X_my_test, shape=(64,64,3))\n",
    "\n",
    "# Data Augmentation (5%*3=15%)\n",
    "X, Y = augment(X, labels=Y, ratio=0.05)\n",
    "\n",
    "# Shuffled Image\n",
    "X, Y = shuffler(X, Y)\n",
    "\n",
    "# One-hot encoding\n",
    "label_map, label_str = label_dict_static(classifier=\"OOP\")\n",
    "Y = np.array(list(map(lambda x: label_map[x], Y)))\n",
    "Y = to_categorical(Y)\n",
    "\n",
    "y_test = np.array(list(map(lambda x: label_map[x], Y_my_test)))\n",
    "y_test_oop = to_categorical(y_test)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "## 4. Split Data in train mode\n",
    "# Train, Val, Test Split\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train_oop, X_val_oop, y_train_oop, y_val_oop = train_test_split(X, Y, test_size=0.2, stratify=Y) \n",
    "print(\"X_train: {}\\ny_train: {}\\nX_val: {}\\ny_val: {}\\nX_test: {}\\ny_test: {}\".format(X_train_oop.shape, y_train_oop.shape, X_val_oop.shape, y_val_oop.shape, X_test_oop.shape, y_test_oop.shape))"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "display_row(X_train_oop, y_train_oop, label_map, label_str)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "## 5. Prepare Training Dummy label\n",
    "\n",
    "#oop_dummy_label_train = np.zeros(shape=(len(y_train_oop),5))\n",
    "weak_dummy_label_train = np.zeros(shape=(len(y_train_oop),2), dtype=float)\n",
    "mask_dummy_label_train = np.zeros(shape=(len(y_train_oop),2), dtype=float)\n",
    "\n",
    "#oop_dummy_label_val = np.zeros(shape=(len(y_val_oop),5))\n",
    "weak_dummy_label_val = np.zeros(shape=(len(y_val_oop),2), dtype=float)\n",
    "mask_dummy_label_val = np.zeros(shape=(len(y_val_oop),2), dtype=float)\n",
    "\n",
    "#oop_dummy_label_test = np.zeros(shape=(len(y_test_val),5))\n",
    "weak_dummy_label_test = np.zeros(shape=(len(y_test_oop),2), dtype=float)\n",
    "mask_dummy_label_test = np.zeros(shape=(len(y_test_oop),2), dtype=float)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import LearningRateScheduler, EarlyStopping, ModelCheckpoint\n",
    "\n",
    "\n",
    "def scheduler(epoch, lr):\n",
    "    if epoch in [5,9,12,20]:\n",
    "        lr = 0.1*lr\n",
    "    return lr\n",
    "\n",
    "adam = Adam(learning_rate=0.001)\n",
    "ls_callback = LearningRateScheduler(scheduler)\n",
    "es_callback = EarlyStopping(monitor='out_oop_val_acc', patience=3)\n",
    "filepath = os.path.join(os.getcwd(), \"ckpt/\", \"Encoder_OOP-{epoch:01d}-{val_acc:.2f}.h5\")\n",
    "checkpoint = ModelCheckpoint(filepath=filepath, monitor='out_oop_val_acc', verbose=1, save_best_only=True, mode='max')\n",
    "\n",
    "fin.compile(optimizer = adam,\n",
    "            loss={'out_oop': 'categorical_crossentropy',\n",
    "                  'out_weak': 'categorical_crossentropy',\n",
    "                  'out_mask': 'categorical_crossentropy'},\n",
    "            loss_weights={'out_oop': 1.0, 'out_weak': 0.0, 'out_mask': 0.0},\n",
    "            metrics={\n",
    "                'out_oop': ['acc', tf.keras.metrics.AUC(thresholds=[0.5,0.7,0.9,0.95])],\n",
    "                'out_weak': ['acc', tf.keras.metrics.AUC(thresholds=[0.5,0.7,0.9,0.95])],\n",
    "                'out_mask': ['acc', tf.keras.metrics.AUC(thresholds=[0.5,0.7,0.9,0.95])]\n",
    "                }\n",
    "            )"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "fin.get_layer('fc2').trainable=False\n",
    "fin.get_layer('fc3').trainable=False\n",
    "fin.get_layer('out_weak').trainable=False\n",
    "fin.get_layer('out_mask').trainable=False\n",
    "fin.summary()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "history = fin.fit(x=X_train_oop, y={'out_oop': y_train_oop, 'out_weak': weak_dummy_label_train, 'out_mask': mask_dummy_label_train},\n",
    "                 epochs=10, batch_size=32, shuffle=True)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "fin.evaluate(X_val_oop, {'out_oop': y_val_oop, 'out_weak': weak_dummy_label_val, 'out_mask': mask_dummy_label_val})"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "X_val_oop.shape, y_val_oop.shape, weak_dummy_label_val.shape, mask_dummy_label_val.shape"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Test using X_test data\n",
    "X_pred=fin.predict(X_test_oop)\n",
    "score(X_pred[0], y_test_oop)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "fig, ax = plt.subplots(1, 3, figsize = (15,5))\n",
    "for i in range(3):\n",
    "    matching_plot(X_test_oop, X_pred[0], y_test_oop, ax[i], label_map, label_str, thd=0.8)\n",
    "plt.show()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "import utils.xai_viz\n",
    "from utils.xai_viz import explainable_model\n",
    "importlib.reload(utils.xai_viz)\n",
    "\n",
    "xai = explainable_model(fin)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "pick = random.randint(0, len(X_test)-1)\n",
    "\n",
    "heatmap = xai.explainable_model(X_test[pick], \"adhesive_conv\", alpha=0.4, output_node=0)\n",
    "fig_title = \"Predicted: {} as {:.3f}\".format(np.argmax(X_pred[0][pick]), X_pred[0][pick][np.argmax(X_pred[0][pick])])  +   \",    Label: {}\".format(np.argmax(y_test[pick]))  \n",
    "plt.title(fig_title)\n",
    "\n",
    "heatmap = xai.explainable_model(X_test[pick], \"adhesive_relu\", alpha=0.4, output_node=0)\n",
    "fig_title = \"Predicted: {} as {:.3f}\".format(np.argmax(X_pred[0][pick]), X_pred[0][pick][np.argmax(X_pred[0][pick])])  +   \",    Label: {}\".format(np.argmax(y_test[pick]))  \n",
    "plt.title(fig_title)\n",
    "\n",
    "\n",
    "heatmap = xai.explainable_model(X_test[pick], \"adhesive_maxpool\", alpha=0.4, output_node=0)\n",
    "fig_title = \"Predicted: {} as {:.3f}\".format(np.argmax(X_pred[0][pick]), X_pred[0][pick][np.argmax(X_pred[0][pick])])  +   \",    Label: {}\".format(np.argmax(y_test[pick]))  \n",
    "plt.title(fig_title)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 2. Weak train using encoder"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "myloader = load_mydata()\n",
    "X_my, Y_my = myloader.load_data(classifier_label=\"Weak\", dsize=(64,64), comp_ratio=4, verbose=0)\n",
    "X_my_test, Y_my_test = myloader.load_test_data(classifier_label=\"Weak\", dsize=(64,64), comp_ratio=4, verbose=0)\n",
    "\n",
    "print(\"My Train set is \", len(Y_my),  \",  My Test set is \", len(Y_my_test))"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "count_man =0\n",
    "count_woman =0\n",
    "\n",
    "for idx, i in enumerate(Y_my):\n",
    "    if ( i == 's0'):\n",
    "        count_man +=1\n",
    "    elif ( i == 's1'):\n",
    "        count_woman+=1\n",
    "\n",
    "count_test_man =0\n",
    "count_test_woman =0\n",
    "\n",
    "for idx, i in enumerate(Y_my_test):\n",
    "    if ( i == 's0'):\n",
    "        count_test_man +=1\n",
    "    elif ( i == 's1'):\n",
    "        count_test_woman +=1\n",
    "\n",
    "fig, (ax1, ax2) = plt.subplots(1,2, figsize=(10,5))\n",
    "plt.suptitle('labeled data distribution(ea)')\n",
    "ax1.set_title('Trainset')\n",
    "ax1.bar(['man','woman'],[count_man, count_woman])\n",
    "\n",
    "ax2.set_title('Testset')\n",
    "ax2.bar(['man','woman'],[count_test_man, count_test_woman])\n",
    "\n",
    "plt.tight_layout()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Normalized Image\n",
    "X = preprocess(X_my, shape = (64,64,3))\n",
    "X_test = preprocess(X_my_test, shape=(64,64,3))\n",
    "\n",
    "# Data Augmentation (5%*3=15%)\n",
    "X, Y = augment(X, labels=Y_my, ratio=0.05)\n",
    "\n",
    "# Shuffled Image\n",
    "X, Y = shuffler(X, Y)\n",
    "\n",
    "# One-hot encoding\n",
    "label_map, label_str = label_dict_static(classifier=\"Weak\")\n",
    "Y = np.array(list(map(lambda x: label_map[x], Y)))\n",
    "Y = to_categorical(Y)\n",
    "\n",
    "y_test = np.array(list(map(lambda x: label_map[x], Y_my_test)))\n",
    "y_test = to_categorical(y_test)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "X_train, X_val, y_train, y_val = train_test_split(X, Y, test_size=0.2, stratify=Y) \n",
    "print(\"X_train: {}\\ny_train: {}\\nX_val: {}\\ny_val: {}\\nX_test: {}\\ny_test: {}\".format(X_train.shape, y_train.shape, X_val.shape, y_val.shape, X_test.shape, y_test.shape))"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "display_row(X_train, y_train, label_map, label_str)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "adam = Adam(learning_rate=0.001)\n",
    "fin.compile(optimizer = adam,\n",
    "            loss={'out_oop': 'categorical_crossentropy',\n",
    "                  'out_weak': 'categorical_crossentropy',\n",
    "                  'out_mask': 'categorical_crossentropy'},\n",
    "            loss_weights={'out_oop': 0.0, 'out_weak': 1.0, 'out_mask': 0.0},\n",
    "            metrics=['acc'])"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "#Dummy target label\n",
    "oop_dummy_label_train = np.zeros(shape=(len(y_train),5))\n",
    "mask_dummy_label_train = np.zeros(shape=(len(y_train),2))\n",
    "\n",
    "oop_dummy_label_val = np.zeros(shape=(len(y_val),5))\n",
    "mask_dummy_label_val = np.zeros(shape=(len(y_val),2))\n",
    "\n",
    "oop_dummy_label_test = np.zeros(shape=(len(y_test),5))\n",
    "mask_dummy_label_test = np.zeros(shape=(len(y_test),2))"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "fin.get_layer('fc1').trainable=False\n",
    "fin.get_layer('fc3').trainable=False\n",
    "fin.get_layer('out_oop').trainable=False\n",
    "fin.get_layer('out_mask').trainable=False\n",
    "\n",
    "fin.summary()\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "history = fin.fit(X_train, {'out_oop': oop_dummy_label_train, 'out_weak': y_train , 'out_mask': mask_dummy_label_train}\n",
    "                    , epochs=4, batch_size=32, shuffle=True)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Test using X_test data\n",
    "X_pred=fin.predict(X_test)\n",
    "score(X_pred[1], y_test)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "fig, ax = plt.subplots(1, 3, figsize = (15,5))\n",
    "for i in range(3):\n",
    "    matching_plot(X_test, X_pred[1], y_test, ax[i], label_map, label_str, thd=0.8)\n",
    "plt.show()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "import utils.xai_viz\n",
    "from utils.xai_viz import explainable_model\n",
    "importlib.reload(utils.xai_viz)\n",
    "\n",
    "xai = explainable_model(fin)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "pick = random.randint(0, len(X_test)-1)\n",
    "\n",
    "heatmap = xai.explainable_model(X_test[pick], \"adhesive_conv\", alpha=0.4, output_node=1)\n",
    "fig_title = \"Predicted: {} as {:.3f}\".format(np.argmax(X_pred[0][pick]), X_pred[0][pick][np.argmax(X_pred[0][pick])])  +   \",    Label: {}\".format(np.argmax(y_test[pick]))  \n",
    "plt.title(fig_title)\n",
    "\n",
    "heatmap = xai.explainable_model(X_test[pick], \"adhesive_relu\", alpha=0.4, output_node=1)\n",
    "fig_title = \"Predicted: {} as {:.3f}\".format(np.argmax(X_pred[0][pick]), X_pred[0][pick][np.argmax(X_pred[0][pick])])  +   \",    Label: {}\".format(np.argmax(y_test[pick]))  \n",
    "plt.title(fig_title)\n",
    "\n",
    "\n",
    "heatmap = xai.explainable_model(X_test[pick], \"adhesive_maxpool\", alpha=0.4, output_node=1)\n",
    "fig_title = \"Predicted: {} as {:.3f}\".format(np.argmax(X_pred[0][pick]), X_pred[0][pick][np.argmax(X_pred[0][pick])])  +   \",    Label: {}\".format(np.argmax(y_test[pick]))  \n",
    "plt.title(fig_title)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "X_my_test, Y_my_test = myloader.load_test_data(classifier_label=\"OOP\", dsize=(64,64), comp_ratio=4, verbose=0)\n",
    "X_test = preprocess(X_my_test, shape=(64,64,3))\n",
    "# One-hot encoding\n",
    "label_map, label_str = label_dict_static(classifier=\"OOP\")\n",
    "y_test = np.array(list(map(lambda x: label_map[x], Y_my_test)))\n",
    "y_test = to_categorical(y_test)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Test using X_test data\n",
    "X_pred=fin.predict(X_test)\n",
    "score(X_pred[0], y_test)\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 3. Mask train using encoder"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "orig_nbformat": 4,
  "language_info": {
   "name": "python",
   "version": "3.6.13",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.6.13 64-bit ('ds_master': conda)"
  },
  "interpreter": {
   "hash": "051845d752917fb819259a0b6fac3e853c795161b2e85e12541c96eac1115414"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}