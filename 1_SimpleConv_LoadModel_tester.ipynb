{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "## 1. Load the model and Test\n",
    "- Before begining, `model_data_argu` dict() is written by hand for setting property"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "source": [
    "# Intialize the tensorflow-gpu <-> physical matching\n",
    "import tensorflow as tf\n",
    "\n",
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "    try:\n",
    "        # Currently, memory growth needs to be the same across GPUs\n",
    "        for gpu in gpus:\n",
    "            tf.config.experimental.set_memory_growth(gpu, True)\n",
    "        logical_gpus = tf.config.experimental.list_logical_devices('GPU')\n",
    "        print(len(gpus), \"Physical GPUs,\", len(logical_gpus), \"Logical GPUs\")\n",
    "    except RuntimeError as e:\n",
    "        # Memory growth must be set before GPUs have been initialized\n",
    "        print(e)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "##############################3 Insert model and Data Properties\n",
    "### be careful when calculating test accuracy, make sure labels_map is same as train phase and test phase(here)\n",
    "model_data_argu = {'label': \"OOP\", 'dsize': (64,64), 'model_name': \"model_oop_cnn\", \"labels_map\": {'c5': 0, 'c0': 1, 'c6': 2, 'c1': 3, 'c7': 4}}"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "source": [
    "# Load Model (Test)\n",
    "from tensorflow.keras.models import load_model\n",
    "import utils.xai_viz\n",
    "from utils.xai_viz import explainable_model\n",
    "import importlib\n",
    "from model.model_cnn import model_cnn\n",
    "import os\n",
    "import numpy as np\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import random\n",
    "from load.load_data import load_mydata\n",
    "\n",
    "myloader = load_mydata()\n",
    "X_my_test, Y_my_test = myloader.load_test_data(classifier_label=model_data_argu['label'], dsize=model_data_argu['dsize'], comp_ratio=4)\n",
    "print(\"My Test set is \", len(Y_my_test))\n",
    "\n",
    "X_test = np.array(X_my_test)/255.0\n",
    "labels_map=model_data_argu[\"labels_map\"]\n",
    "\n",
    "Y_my_test = np.array(list(map(lambda x: labels_map[x], Y_my_test)))\n",
    "Y_test = to_categorical(np.array(Y_my_test))\n",
    "print(labels_map)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "print(X_test.shape, Y_test.shape)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "model_load = load_model(\"./ckpt/\"+model_data_argu[\"model_name\"])\n",
    "xai = explainable_model(model_load)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "X_pred=model_load.predict(X_test)\n",
    "# Test using X_test data\n",
    "def score(preds, labels):\n",
    "    ret=0\n",
    "    for pred, label in zip(preds, labels):\n",
    "\n",
    "        pred_idx = np.argmax(pred)\n",
    "        label_idx = np.argmax(label)\n",
    "\n",
    "        if (pred_idx == label_idx):\n",
    "            ret+=1\n",
    "\n",
    "    ret = ret / len(preds)\n",
    "    return ret\n",
    "\n",
    "print(\"Test Predict is: {}%\".format(score(X_pred, Y_test)*100))"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "#2. (모델2: OOP + phoning**) 기존 오픈데이터셋의 라벨링 활용 가능 safe driving(c0), reaching behind(c7)\n",
    "#                           ,phoning(c2,c4), texting(c1,c3)은 휴대폰 하고 있는 것으로 퉁쳐서 c1으로 클래스 구분하자\n",
    "#                           -추가로 데이터 추가하고 클래스가 없는 too close(c5) / too far(c6)는 데이터 만들어야 겠네\n",
    "\n",
    "delta = random.randint(0,10)\n",
    "d =0\n",
    "\n",
    "for pick, i in enumerate(Y_test):\n",
    "    if ( (np.argmax(i)==2) and (np.argmax(X_pred[pick])== np.argmax(i))):\n",
    "        d+=1\n",
    "        if ( d> delta):\n",
    "            print(X_pred[pick])\n",
    "            break\n",
    "\n",
    "heatmap = xai.explainable_model(X_test[pick], \"2nd_relu\", alpha=0.4)\n",
    "fig_title = \"Predicted {} as {:.2f}prob\".format(np.argmax(X_pred[pick]) , np.max(X_pred[pick])) + \",  Label(GT): {}\".format(np.argmax(Y_test[pick]))\n",
    "plt.title(fig_title)\n",
    "heatmap = xai.explainable_model(X_test[pick], \"3rd_conv\", alpha=0.6)\n",
    "fig_title = \"Predicted {} as {:.2f}prob\".format(np.argmax(X_pred[pick]) , np.max(X_pred[pick])) + \",  Label(GT): {}\".format(np.argmax(Y_test[pick]))\n",
    "plt.title(fig_title)\n",
    "heatmap = xai.explainable_model(X_test[pick], \"3rd_maxpool\", alpha=0.8)\n",
    "fig_title = \"Predicted {} as {:.2}fprob\".format(np.argmax(X_pred[pick]) , np.max(X_pred[pick])) + \",  Label(GT): {}\".format(np.argmax(Y_test[pick]))\n",
    "plt.title(fig_title)\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 2. Just Inferencing without Label"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "### No label data(test)\n",
    "from load.load_data import load_opendata\n",
    "\n",
    "openloader = load_opendata()\n",
    "X_open_test, Y_open_files = openloader.load_data(classifier_label=None, dsize=(64,64), comp_ratio=30)\n",
    "\n",
    "print(\"My Test set(No Label) is \", len(X_open_test))\n",
    "X_open_test = np.array(X_open_test)/255.0"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "X_open_pred = model_load.predict(X_open_test)\n",
    "print(X_open_pred.shape)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# labels_map={'c5': 0, 'c0': 1, 'c6': 2, 'c1': 3, 'c7': 4}\n",
    "#2. (모델2: OOP + phoning**) 기존 오픈데이터셋의 라벨링 활용 가능 safe driving(c0), reaching behind(c7)\n",
    "#                           ,phoning(c2,c4), texting(c1,c3)은 휴대폰 하고 있는 것으로 퉁쳐서 c1으로 클래스 구분하자\n",
    "#                           -추가로 데이터 추가하고 클래스가 없는 too close(c5) / too far(c6)는 데이터 만들어야 겠네\n",
    "# pick = random.randint(0, len(X_open_test)-1)\n",
    "\n",
    "delta = random.randint(0,100)\n",
    "d =0\n",
    "for pick, i in enumerate(X_open_pred):\n",
    "    if  (np.argmax(i)==4):\n",
    "        d+=1\n",
    "        if ( d> delta):\n",
    "            break\n",
    "\n",
    "heatmap = xai.explainable_model(X_open_test[pick], \"2nd_relu\", alpha=0.4)\n",
    "fig_title = \"Predicted {} as {:.2f}prob\".format(np.argmax(X_open_pred[pick]) , np.max(X_open_pred[pick]))\n",
    "plt.title(fig_title)\n",
    "heatmap = xai.explainable_model(X_open_test[pick], \"3rd_conv\", alpha=0.6)\n",
    "fig_title = \"Predicted {} as {:.2f}prob\".format(np.argmax(X_open_pred[pick]) , np.max(X_open_pred[pick]))\n",
    "plt.title(fig_title)\n",
    "heatmap = xai.explainable_model(X_open_test[pick], \"3rd_maxpool\", alpha=0.8)\n",
    "fig_title = \"Predicted {} as {:.2}fprob\".format(np.argmax(X_open_pred[pick]) , np.max(X_open_pred[pick]))\n",
    "plt.title(fig_title)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "tf.keras.utils.plot_model(\"\", show_shapes=True)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "orig_nbformat": 4,
  "language_info": {
   "name": "python",
   "version": "3.6.13",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.6.13 64-bit ('ds_master': conda)"
  },
  "interpreter": {
   "hash": "051845d752917fb819259a0b6fac3e853c795161b2e85e12541c96eac1115414"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}