{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Intialize the tensorflow-gpu <-> physical matching\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "    try:\n",
    "        # Currently, memory growth needs to be the same across GPUs\n",
    "        for gpu in gpus:\n",
    "            tf.config.experimental.set_memory_growth(gpu, True)\n",
    "        logical_gpus = tf.config.experimental.list_logical_devices('GPU')\n",
    "        print(len(gpus), \"Physical GPUs,\", len(logical_gpus), \"Logical GPUs\")\n",
    "    except RuntimeError as e:\n",
    "        # Memory growth must be set before GPUs have been initialized\n",
    "        print(e)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "from load.load_data import load_opendata\n",
    "from load.load_data import load_mydata\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import random"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "openloader = load_opendata()\n",
    "X_open, Y_open = openloader.load_data(classifier_label=None, dsize=(64,64), comp_ratio=4)\n",
    "\n",
    "myloader = load_mydata()\n",
    "X_my, Y_my = myloader.load_data(classifier_label=\"OOP\", dsize=(64,64), comp_ratio=10, verbose=0)\n",
    "X_my_test, Y_my_test = myloader.load_test_data(classifier_label=\"OOP\", dsize=(64,64), comp_ratio=4, verbose=0)\n",
    "\n",
    "print(\"Open data is \", len(X_open),\", My Train set is \", len(Y_my),  \",  My Test set is \", len(Y_my_test))"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "import numpy as np\n",
    "from utils.process import preprocess, noise, augment, tsne_plot, display_pair, shuffler\n",
    "\n",
    "# Normalized Image\n",
    "X = preprocess(X_open, shape = (64,64,3))\n",
    "\n",
    "# Data Augmentation (5%*3=15%)\n",
    "X = augment(X, ratio=0.05)\n",
    "\n",
    "# Shuffled Image\n",
    "X = shuffler(X)\n",
    "\n",
    "# Noise Image\n",
    "Noise_X = noise(X)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "display_pair(X,Noise_X)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Train, Val, Test Split\n",
    "X_train = X[:int(len(X)*0.9)]\n",
    "X_val = X[int(len(X)*0.9):]\n",
    "\n",
    "print(X_train.shape)\n",
    "print(X_val.shape)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import LearningRateScheduler, EarlyStopping, ModelCheckpoint\n",
    "import model.model_autoencoder\n",
    "from model.model_autoencoder import model_autoencoder\n",
    "import importlib\n",
    "importlib.reload(model.model_autoencoder)\n",
    "\n",
    "import tensorflow as tf\n",
    "import os\n",
    "\n",
    "\n",
    "def scheduler(epoch, lr):\n",
    "    if epoch in [5,9,12,20]:\n",
    "        lr = 0.1*lr\n",
    "    return lr\n",
    "    \n",
    "autoencoder = model_autoencoder(input_shape = (64, 64, 3))\n",
    "adam = Adam(learning_rate=0.001)\n",
    "ls_callback = LearningRateScheduler(scheduler)\n",
    "es_callback = EarlyStopping(monitor='val_loss', patience=3)\n",
    "filepath = os.path.join(os.getcwd(), \"ckpt/\", \"Autoencoder_fine-{epoch:01d}-{val_loss:.2f}.h5\")\n",
    "checkpoint = ModelCheckpoint(filepath=filepath, monitor='val_loss', verbose=1, save_best_only=True, mode='min')\n",
    "\n",
    "autoencoder.compile(loss = 'mse', optimizer = adam)\n",
    "autoencoder.summary()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "autoencoder.fit(x=X_train, y = X_train, epochs=30, batch_size=32, shuffle=True, validation_data=(X_val, X_val), callbacks=[ls_callback, es_callback, checkpoint])"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Save Model\n",
    "autoencoder.save('./ckpt/model_oop_autoencoder_fine')"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Display the train data and a version of it with added noise\n",
    "predictions = autoencoder.predict(Noise_X[len(Noise_X)*0.9:])"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "display_pair(Noise_X[len(Noise_X)*0.9:], predictions)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "orig_nbformat": 4,
  "language_info": {
   "name": "python",
   "version": "3.6.13",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.6.13 64-bit ('ds_master': conda)"
  },
  "interpreter": {
   "hash": "051845d752917fb819259a0b6fac3e853c795161b2e85e12541c96eac1115414"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}